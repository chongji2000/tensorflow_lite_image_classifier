{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Invalid alias: The name clear can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name more can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name less can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name man can't be aliased because it is another magic command.\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
    "!tar -zxvf flower_photos.tgz\n",
    "!rm -rf images\n",
    "!mv flower_photos images\n",
    "!rm images/LICENSE.txt\n",
    "!rm -rf images/daisy\n",
    "!rm -rf images/roses\n",
    "!rm -rf images/tulips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1279 images belonging to 2 classes.\n",
      "Found 318 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0716 03:31:35.657920 139989764822848 deprecation.py:323] From /srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/128 [>.............................] - ETA: 14:03 - loss: 0.6702 - accuracy: 0.6200"
     ]
    }
   ],
   "source": [
    "# 此例子是使用tensorflow框架结合MobileNet V2模型，在imagenet预训练参数下微调成一个图像分类器。\n",
    "# 1、需要安装最新版的tensorflow 当前为pip install tensorflow==2.0.0-beta1\n",
    "# 2、base_dir是放图片目录，此目录下还有许多子目录，每个子目录存放一个类别的图像\n",
    "# 3、此例子在mybinder运行，只是为了演示，实际训练请修改BATCH_SIZE，EPOCHS或者其它代码\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "base_dir=\"images\"\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 10 #64\n",
    "EPOCHS=1 #30\n",
    "\n",
    "#创建一个样本增强生成器，validation_split即为训练集与验证集比例是8:2\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    validation_split=0.2)\n",
    "\n",
    "#创建训练集生成器，使用枚举“training”指定\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE, \n",
    "    subset='training')\n",
    "\n",
    "#创建验证集生成器，使用枚举“validation”指定\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE, \n",
    "    subset='validation')\n",
    "\n",
    "#根据子文件夹名来生成标签\n",
    "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
    "\n",
    "with open('labels.txt', 'w') as f:\n",
    "  f.write(labels)\n",
    "\n",
    "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "#载入预训练模型MobileNet V2，去除顶部原有分类器用于做fine-tune,并指定基础模型的采用imagenet数据集进行预训练。\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                              include_top=False, \n",
    "                                              weights='imagenet')\n",
    "\n",
    "#先把基础模型所有层设为可训练（所有的层参与训练）\n",
    "base_model.trainable = True\n",
    "\n",
    "#所有层都训练就太慢了，所以从100层以后的参数可以训练比较快。\n",
    "fine_tune_at = 100\n",
    "#把基础模型的前100层都冻结不参与训练\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False\n",
    "\n",
    "#在基础模型上添加一个自己的简单分类器\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(len(train_generator.class_indices.keys()), activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#加上损失函数与优化器\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(1e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#训练\n",
    "history_fine = model.fit(train_generator, \n",
    "                         epochs=EPOCHS,\n",
    "                         validation_data=val_generator)\n",
    "\n",
    "#保存模型\n",
    "saved_model_dir = 'save/fine_tuning'\n",
    "if os.path.isdir(saved_model_dir):\n",
    "    shutil.rmtree(saved_model_dir)\n",
    "tf.saved_model.save(model, saved_model_dir)\n",
    "\n",
    "#转换模型为tflite\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "#保存tflite模型文件\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "print(\"ok\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
